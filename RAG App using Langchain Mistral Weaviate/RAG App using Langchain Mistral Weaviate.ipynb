{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "WEAVIATE_API_KEY = os.getenv(\"WEAVIATE_API_KEY\")\n",
    "WEAVIATE_CLUSTER = os.getenv(\"WEAVIATE_CLUSTER\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weaviate client initialized successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\weaviate\\warnings.py:121: DeprecationWarning: Dep005: You are using weaviate-client version 3.24.0. The latest version is 4.10.4.\n",
      "            Please consider upgrading to the latest version. See https://weaviate.io/developers/weaviate/client-libraries/python for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "import os\n",
    "\n",
    "WEAVIATE_URL = os.getenv(\"WEAVIATE_CLUSTER\")\n",
    "WEAVIATE_API_KEY = os.getenv(\"WEAVIATE_API_KEY\")\n",
    "\n",
    "client = weaviate.Client(\n",
    "    url=WEAVIATE_URL,\n",
    "    auth_client_secret=weaviate.AuthApiKey(api_key=WEAVIATE_API_KEY)\n",
    ")\n",
    "\n",
    "print(\"Weaviate client initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikas\\AppData\\Local\\Temp\\ipykernel_7272\\207400733.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "c:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embedding_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "#model_kwargs = {\"device\": \"cuda\"}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "  model_name=embedding_model_name,\n",
    "  #model_kwargs=model_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"RAG_From_Scratch.pdf\",extract_images=True)\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1'}, page_content=\"Retrieval Augmented' Generation(RAG)\\nWhat you will learn:\\n1. Introduction of RAG.\\n2. RAG Architecture.\\ninqeshon\\n3. End to End RAG Pipeline.\\n4. Advantage Disadvantage of RAG.\\n5. Build RAG from Scratch.\\n6.Multimodal RAG:\\n7. RAG v/s Finetuning.\\n8.EvaluationMatricesof RAG.—\\n9. How to improve RAG system and Important research Paper.\\nGT=\\n2022\\nDPx\\nekn\\nL人m+'o+her tifo CDoc → De)\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 1, 'page_label': '2'}, page_content='1.Introduction:WhatisRAG?\\nRAG is called Retrieval augmented generation, is an architecture used to help LLMs model like gpt- 4,\\nGemini, Gemma,LLAMA2, MISTRAL to provide a-better response by using relevant information from\\nadditional sources andreduces thechancethatllm-willleadtoincorrectinformation\\nor\\nRAG is a technique that enhances language model generation by incorporating external knowledge.This\\nis typically doneby retrievingrelevantinformation from alarge corpus of documents and usingthat\\ninformation to inform-the generation process.\\nor\\nWith RAG, the LLM is able to leverage knowledge and information that is not necessarily in its weights\\n means it is not inside the training.\\nfrsq= hse\\n·)\\nWhy we should use RAG?\\n1:Limitedknowledgeaccess\\nLack of transparency: LLMs struggle to provide transparent or relevant information\\n3.Hallucinationsinanswers\\n2.RAG Architecture.\\n1. Ingestion\\n2. Retrieval\\n3. Generation\\nArchitecture\\nL0,1 0.3 0.33\\nQuestion\\ntextchunk\\nEmbedbingy -1\\ncResar\\nueryEmbedeling\\nBuild\\nEmlbedking-2\\nSemantic\\nL0,1 0.3 0.33\\nExtractData/\\ntextchunk2\\nIndex\\nLLMGenerative\\nContent\\n10.30.3]\\nemanticSearch\\ntextchuk3\\nEmbedbing -3\\n[90h050]\\nLO.5 0.4 0.5]\\nnowledlge\\nRanked\\nEmbedeing-10\\nBase\\ntextchunk10\\nResults\\nQetaiva/ -)  6btaintnq\\nfhe dt frm D\\nAuq ment \\nehching.inf。\\nusmq.\\n心。\\nPronP)\\ngehrihon\\n人M\\nLkshq \\ncpr-'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 2, 'page_label': '3'}, page_content='embedd inq\\ny(oar)\\n√echr.=)\\nicar\\n[%]\\nP2=)[x0]\\nP3e [oy]\\nX\\n(ysom\\nower\\n<rng\\nTueeh\\n0.S.\\nMan°\\n0.13\\nSimlM\\nn\\nCosrhie smilanly\\necuLrdia \\nJaccare\\nFruil.\\nApple\\n[T,r]=[]\\nuys了\\n[][]\\n: Tech\\nSimiM?\\nhp 0@\\nCoSme =) Cos 90°'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 3, 'page_label': '4'}, page_content=\"3.End toEnd RAGPipeline.\\nLet'ssummariestheprocessofRAG:\\nBasic RAG Pipeline\\nIngestion\\nDocuments\\nEmbeddings\\nChunks\\nIndex\\nRetrieval\\nSynthesis\\nIndex\\nTopK\\nQuery\\nLLM\\nResponse\\nRAG Flow:A StepbyStep Representation\\nFigure 1 demonstrates thestepsinvolvedinbuildinga RAGpipeline:\\nLegend\\nExtraction， chunking\\nEnterprise Data Store \\nDatabricks, Anyscale, LangChan\\nContextual data\\nAIWS,MictosoftGoogleOracieDatabricks,\\nSnowllake MongoDB,CouchoB,DataStax\\nNotion, Codae, Salesforoe, JiRA, eto\\nUser Query\\nMany others.\\nRetrieval engine\\nAction\\nText Storage DB\\nApp hosting\\nVercel,streamlit, Gradio,\\nreplit, fly.io\\nector Store /DB\\nQdrantPine\\nme,zl\\nEmbedding LLM\\na,P9N\\nOpenAiLCohere,\\nHuggingface\\nQuery\\nLLM hosting \\nMLOps\\nResponse\\nMLlow, W&B, Aim\\nConstruet prompt\\nLLM hosting\\nLangchein, Rebuff, DIY\\nOperALCohere,Anthropic\\nAzure, AWS, GCP\\nEnterprise App Automation\\nepiea asuodsa\\nZapier,JIRAtionod\\nAsana, Monday, email, etc\\nNvidia Guardrails\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 4, 'page_label': '5'}, page_content=\"A.).LetsunderstandtheIngestionprocess\\n1.Document:\\nIn a typical RAG pipeline, we have knowledge sources, such as Local Files, CSV, TSV, JSON, PDF, DOCs, Web pages,\\nXML,Databases,Cloud Storage,AnyRemoteLocation etc.\\n2. Chunking:\\nWe collect the data from yarious sources, split the data,into the chunks.\\nWhy chunking is required?\\nWe can fed the entire document alsobut why we are just passing the paragraph so here the reason is\\n1. LLM will rt be overloaded with information and\\nCcmini?.\\n)p9)\\n(GpT\\n2.Evenit ishaving somelimitsinterms oftokens\\nHow tofiguring out theIdeal ChunkSize\\nToo small a chunk won't provide you info. It is not sufficient and These chrunks can be defined either by a fixed size, such\\nas a specific number of characters, sentences or paragraphs.\\nLarger chunks might include irrelevant information,\\nintroducing noise and potentially\\nHeducing the retrieval accuracy.By\\ncontrollinft\\nthechunksize\\nRAGcanmaintainabalancebetweencomprehensivenessandprecision.\\nBased on these factor you can' decide the size of chunk.\\nDa+s - CorP.as\\n1. DataCharacteristics\\nChuiic -) Doce amenlh.\\ntdc\\n2.Retriever Constraints\\n(s+n+ece)\\n3.Memory and Computational Resources\\n4TaskRequirements\\n5.Experimentation\\n6. OverlapConsideration\\n@hanics =) fokeins (wora )\\nhttps://www.pinecone.io/learn/chunking-strategies/\\nSenter o ( Doc, Chan k)\\nWo -d (T)\\nParagraa\\n3. Embedding\\nAfter chunking we convert it into vector embedding. vector embeddingare numerical representations of the data.\\nTypes of embedding\\n1. Frequency based embedding\\nSe menh\\nBOW\\nmbeddrng\\nTF-IDF\\nN-GRAMS\\n>2. Neural Network based embeddings\\nWord2Vec\\nfasttext\\nBert\\nElmo\\nOPEN AI Embedding\\nGeminiEmbedding\\nToken level embedding vs Sentence level embedding.\\nCheckout the link: https: //huggingface.co/sentence-transformers\\nhttps://www.sbert.net/\\nwhich embedding model you need to select:\\nCheckouttheleaderboard:https://huggingface.co/spaces/mteb/leaderboard\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6'}, page_content=\"howsentencetransformersdiffercomparedtotoken-levelembeddingmodelssuchasBERT?\\nSentence transformers are specifically optimized for producing representations at the sentence level, focusing o\\ncapturing the overall semantics of sentences,which makes them particularly useful for tasks involving sentence similarit\\nand clustering. This contrasts with token-level models like BERT, which aremore focused on understanding an\\nrepresentingthemeaningofindividualtokenswithintheirwidercontext.\\n4. Vector Embedding Indexing\\ndimensionalvectordata,enablingfastsimilaritysearchesandnearestneighborqueries.\\nCheckout the link: https://www.datastax.com/guides/what-is-a-vector-index\\nAvectordatabase\\nindexes\\nandstores\\nvectorembeddings\\nvector indexing\\nfor fast retrieval\\nand similanitysearch.\\nIndex\\nJembecldlings\\n40.70.90.10.5\\n20.30.80.70.3\\n0.60.40.30.2\\nunstructuredl\\ndata\\n0.30.20.10.9\\ndatastructure\\nofteninclucingadistancemetric\\n5.Database or Retriever:\\nTheretriever herecould beanyof thefollowingdependingontheneed\\nVectordatabase:Avectordatabaseindexesandstoresvectorembeddingsforfastretrievalandsimilaritysearch,with\\ncapabilities like CRUD operations, metadata filtering, horizontal scaling, and serverless.\\nGraph database:\\nGraph databases are designed to represent and store data as graphs.This makes it easy to represent\\npeople, products, and events along with what ties them together. Search engines, logistics businesses, and social networks\\ntypically.usegraphdatabasestounderstandconnectionsintheirdata.\\nNodes are the primary entities in a graph database. Each node holds all data about a person, product, business, event, or\\nanother entity.\\nEdges are theconnecting parts of graph databases. They showsimilarities, relationships, and commonalities.You can\\ndefine the properties and weights of edges tofit your purpose.\\nPegularSQLdatabase:Offersstructureddatastorageandretrievalbutmightlackthesemanticflexibilityofvector\\ndatabases.\\nGraph databases bring you the fullpower of relationships in data.\\nVector databases arebest suited for managing and querying high-dimensional data in use cases that require similarity\\nsearches.\\nIt can behard tomake theMice andgowith eithergraph or vector technology foryour database.Withgenerative AI,\\nlarge language models (LLM), and real-time data playing an increasing part in modern applications, we're seeing an\\nincreaseincombined solutions\\nWith generative AI, large language models (LLM), and real-time data playing an increasing part in modern applications,\\nwe'reseeinganincreasein'combinedsolutions.\\nThis is why Nee4j recently added the ability to perform vector similarity search.They aim to make more sense of data and\\ngraph\\ncheckout thelink:https://superlinked.com/vector-db-comparison/\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 6, 'page_label': '7'}, page_content=\"B).Let'sUnderstandtheretrievalprocess\\nStandardnaiveapproach\\nIn a basic RAG Pipeline\\nDocuments\\nChunks\\nThesametextchunksused in\\nembeddingsandsynthesis.\\nEmbeddingforretrieval\\nSynthesis\\ntasks\\nTopK\\nretrieved\\nEmbeddings\\nchunks\\nLLM\\nResponse\\nBut:\\nEmbedding-basedretrievalworkswellwith\\nsmallertextchunks.\\nThe standard pipeline uses the same text chunk for indexing/embedding as well as the output synthesis.\\nAdvantages:\\n·Simplicity and Efficiency\\n· Uniformity in Data Handling\\nDisadvantages:\\n·Limited Contextual Understanding\\n·PotentialforSuboptimalResponses\\nSentence-WindowRetrieval / Small-to-Large.Chunking\\nInSentence-windowretrieval\\npipeline\\ncontext\\nDocuments\\nChunks\\nsmaller\\nContextaroundthechunks\\nchunks\\naddedtotheretrievedones\\nEmbeddingforretrieval\\nSynthesis\\ntasks\\nTopK\\nretrieved\\nEmbeddings\\nchunks\\nLLM\\nResponse\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 7, 'page_label': '8'}, page_content='During retrieval, we retrieve the sentences that are most relevant to the query via similarity search and replace the\\nsentence withthefull surrounding context(using a static sentence-window around the context,implemented by\\nretrievingsentencessurroundingtheonebeingoriginallyretrieved)\\nSentence-windowretrieval\\nQuery:Whatarethe\\nconcernssurrounding\\ntheAMOC?\\nContinuousobservationof theAtlantic\\nmeridionaloverturning circulation（AMoc)\\nhasimproved theunderstanding of its\\nvariability（Frajka-Williams et al,2019),but\\nthereislowconfidenceinthequalificationof\\nAMOC changesinthe2oth centurybecause\\nof lowagreementinquantitative\\nWhat theLLM sees\\nreconstructed andsimulated trends.Direct\\nobservationalrecords since the mid-2000s\\nremaintooshorttodetermine therelative\\ncontributions of internal variability,natural\\nforcingandanthropogenictoAMocchange\\n(highconfidence).Overthe 2lstcentury\\nAMOCwill very likelydeclineforallSsp\\nEmbeddingLookup\\nscenariosbutwillnotinvolveanabrupt\\ncollapsebefore2100.3.2.2.4Sea IceChanges\\nSea ice is akey driver of polar marine life,\\nhosting unique ecosystems and affecting\\ndiversemarineorganismsandfoodwebs\\nthroughitsimpactonlightpenetrationsand\\nWhattheLLMsees\\nsuppliesof nutrientsandorganicmatter(\\nArrigo, 2014).\\nAdvantages:\\n·Enhanced Specificity in Retrieval\\n·Context-Rich Synthesis\\n·Balanced Approach\\nDisadvantages:\\n?Increased Complexity\\nAuto-mergingRetriever/HierarchicalRetriever\\nAuto-merging retrieval\\nChunk\\nChunk\\n(512)\\n(512)\\nChunk\\nChunk\\nChunk\\nChunk\\n(128)\\n(128)\\n(128)\\n(128)\\nChunk\\nChunk\\nChunk\\nChunk\\n(128)\\n(128)\\n(128)\\n(128)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 8, 'page_label': '9'}, page_content=\"Auto-mergingretrieval aimsto.combine(or merge)informationfrommultiple sources orsegments of text tocreate a\\nmore comprehensive and contextually relevant response to a query.This approach isparticularly useful when no single\\ndocument orsegmentfully answersthequerybutrather the answerliesin combininginformationfrommultiplesources.\\nIt allows smaller chunks to be merged into bigger parent chunks. It does this via the following steps:\\nDefineahierarchyofsmallerchunkslinkedtoparentchunks:\\nIf the set of smaller chunks linking to a parent chunk exceeds some threshold (say,cosine similarity),then“merge\\nsmaller chunks into thebigger parent chunk.\\nThe methodwillfinallyretrievetheparentchunkforbettercontext.\\nAdvantages:\\n·ComprehensiveContextualResponses\\n·ReducedFragmentation\\n· Dynamic Content Integration\\nDisadvantages:\\n·Complexity in Hierarchy and Threshold Management\\n·Risk of Overgeneralization\\n·Computational Intensity\\nEnsemble Retrieval and Re-Ranking\\nAll documerts\\nQuery\\nJerry Liu\\n@jeryjliue\\nMM？\\nVector\\nIf you 1) already know RAG basics, and 2) want to become a superstar Al\\nDB\\nengineer, then learn to build advanced RAG from scratch \\nExcited to launch a new category of @llamaindex tutorials on this exact\\ntopic：\\nlearn advanced IR/Al concepts\\ntacklemore complex userqueries\\nImprove accuracy + reduce hallucination\\nIn this first part, we teach youhow to build a RAG-Fusion pipeline:\\nenables dynamic retrieval over complex questions.\\nA two=stage ret\\nQuery generation/rewriting\\n2Ensemble retrieval\\n3Reciprocal RankFusion\\nAllthese steps are based off core retrieval principles, designed to\\nimprove precision/recall for different user queries.By learning this, you'll\\nswess gg ino Bujzjwgdo jo, suoynul/sjoo au uje\\nLearnByBullding.Al\\nUserQuery\\nRetriever1\\nRetriever2\\nRetriever3\\nChunk size:128\\nChunk size:512\\nChunk size:1024\\nChunk(128)\\nChunk(512)\\nChunk(128)\\nChunk(1024)\\nChunk（512)\\nChunk(1024)\\nReranker\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 9, 'page_label': '10'}, page_content=\"Let's Understand the augmentation andgeneration\\nResponseGeneration/Synthesis\\nUser Input: A user provides a query in natural language, seeking an answer or completion.\\nInformationRetrieval:Theretrievalmechanismscansthevectordatabasetoidentifysegmentsthataresemantically\\nsimilar to the user's query (which is also embedded).These segments are then given to the LLM to enrich its context for\\ngeneratingresponses.\\nCombining Data: The chosen data'segments from the database are combined with the user's initial query, creating an\\nexpandedprompt.\\nGenerating Text: The enlarged prompt, filled with added context, is then given to the LLM, which crafts the final, context-\\nawareresponse.\\nThis process involves integrating the insights gleaned from various sources, ensuring accuracy and relevance, and crafting\\na response that is not only informative but also aligns with the user's original query, maintaining a natural and\\nconversationaltone.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 10, 'page_label': '11'}, page_content=\"Benefits of RAG:\\n·With-RAG, the LLM is able to leverage knowledge and information that is not necessarily in its weights, providing it\\naccesstoexternalknowledgebases.\\n· Improved relevance and accuracy:\\n·Handling open-domain queries:\\n·Reduced generation bias:\\n·Multi-modal capabilities:\\n·image captioning, content summarization\\n.Human-AI Collaboration:\\n·RAGdoesn'trequiremodelretraining,savingtime andcomputationalresources.\\nIn summary, RAG models are well-suited for applications where there's a lot of information available, but it's not neatly\\norganised or labelled.\\nDisadvantage:\\nRAG's performance depends on the comprehensiveness and correctness of the retriever's knowledge base.\\nInformationLoss\\nIf welook at the chain of processes in theRAG system:\\n1.Chunkingthe.textandgeneratingembeddingforthechunks\\n2.Retrievingthechunksbysemanticsimilaritysearch\\n3.Generateresponsebasedonthetextofthetop_kchunks\\nWayofcreatingaRAG.\\nRAG libraries and frameworks\\nBuild your onRAGfromscratch\\nLang chain\\nLlama Index.\\nHaystack: End-to-end RAG framework for document search provided by Deepset\\nREALM: Retrieval Augmented Language Model (REALM) training is a Google toolkit for\\nopen-domain question answering with RAG.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 11, 'page_label': '12'}, page_content=\"RAG(Retrieval Augmented Generation)Cheatsheet\\nStages in RAG:\\nKey Concepts:\\n1.Loading:\\n1.Nodes and Documents:\\n Imgort your data (text fles, PFs, databases, APIs using Lamaub’s extense range f\\nFundamental units in Llamatndex, where Documents encapsulate data sources and Nodes represent\\nconnectors.\\ndata “chunks* with associated metadata.\\n2.Indexing:\\n1.Connectors:\\nCreate searchable data structures, primarlythrouh vecterembeddings andmetadata strateies,\\nBridge arious dataseurce int the RAG frmwrk, transfrming theint odes and cume\\neapa xaas tuaa fuqeua\\n1.Indexes:\\n3.Storing:\\no Securely store your indexed data and metadata for quick access without the need to re-index.\\nmetadata.\\n4.Querying:\\n1.Embeddings:\\no Utilize LLMs and Llamalndex data structures for diverse querying techniques, including sub-\\nNumerical representations of data, facilitating the relevance fitering preces.\\nqueries and hybrid strategies.\\n1.Retrievers:\\n5.Evaluation:\\nDefine efficient retrieval strategles, ensuring the relevancy and efficiency of deta retrieval.\\n Continuouslyassess the effectiveness of your pipeline to ensure accuracy, faithflness, and\\n1.Routers:\\npaads asuodsai\\nManage the selectien f appropriate retrievers based on query speciis and metaata.\\n1.Node Postprocessors:\\nApply transformations or re-ranking logic to refine the set of retrieved nodes.\\n1.Response Synthesizers:\\nApplicationTypes:\\nCraft responses from the LLM, util\\n1.Query Engines:\\n For dinect question-answering over your data.\\n2.Chat Engines:\\nLlamalndex\\nSingleStore\\n Enables coversations with your data for an interactive experience.\\n3.Agents:\\nAutomated decision-makers that interact with external too\\nadaptable for complex tasks.\\nLangChain\\nOpenAl\\nConstructior\\nRetrieval\\nRelationalDBs\\nGraphDBs\\nVectorbBs\\nRarking\\nRefinerent\\nestien→\\nduestion→\\nGuestio\\nText-to-SQL\\nText-to-Cypher\\nSelf-query retriever\\nal Language to SQL\\nNatural Language to Cypher\\nAuto-generatemetadata\\nd/orSQLw/PGVector\\nquery Langugage for GraphDBs\\nfilters fron query\\nRe-Rank,RankGPT,RAG-Fusion\\nCRAG\\nQuery\\nTranslation\\nRank or filter/compress docu\\nments based on relevance\\nQuery Decomposition\\nPsuedo\\neuments\\nAetiveretieval\\nCRAG\\nQuestion\\nQuestion\\nMulti-query, Step-back, RAG-Fusion\\nHyDE\\nRe-retrieve and/or retrive fron new data sources\\n(e.g.,wb）if retrieved documents aze not relevant\\nDecompose or re-phrase the input question\\nHypothetical documents\\nyeog\\nDiagramcreditLangchain\\nQuestion\\nAnswer\\nRelationalDB\\nDocuments\\nSteveNouri\\npt\\nVeetorstore\\nPrompt#2\\nLet LLM choose DB based\\nEnbed question and choose\\non the question\\nprompt based on sinilarity\\nIncl\\nGeneration\\nChunk Optimization\\nMulti-representation\\nHeirachicalIndeing\\nActiveretieval\\nCharecters\\nSectiors\\nSenant'ic\\nT'0]\\nDeliniters\\nSelf-RAG, RRR\\nSenantic Splitter\\nParent Document,Dense X\\nFine-tuning,ColBERT\\nRAPTOR\\nOptimize chunk size\\nConvert documents into compact\\nDomain-specific and/or\\nTree of document sumnarization\\nUse generation quality to inform\\nused for eabedding\\nretrieval units （e.g.,a sunmary)\\nadvanced enbedding model.s\\nat various abstraction Levels\\nquestion re-writing and/or\\nre-retrieval of documents\")]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=20)\n",
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1'}, page_content=\"Retrieval Augmented' Generation(RAG)\\nWhat you will learn:\\n1. Introduction of RAG.\\n2. RAG Architecture.\\ninqeshon\\n3. End to End RAG Pipeline.\\n4. Advantage Disadvantage of RAG.\\n5. Build RAG from Scratch.\\n6.Multimodal RAG:\\n7. RAG v/s Finetuning.\\n8.EvaluationMatricesof RAG.—\\n9. How to improve RAG system and Important research Paper.\\nGT=\\n2022\\nDPx\\nekn\\nL人m+'o+her tifo CDoc → De)\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 1, 'page_label': '2'}, page_content='1.Introduction:WhatisRAG?\\nRAG is called Retrieval augmented generation, is an architecture used to help LLMs model like gpt- 4,\\nGemini, Gemma,LLAMA2, MISTRAL to provide a-better response by using relevant information from\\nadditional sources andreduces thechancethatllm-willleadtoincorrectinformation\\nor\\nRAG is a technique that enhances language model generation by incorporating external knowledge.This\\nis typically doneby retrievingrelevantinformation from alarge corpus of documents and usingthat'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 1, 'page_label': '2'}, page_content='information to inform-the generation process.\\nor\\nWith RAG, the LLM is able to leverage knowledge and information that is not necessarily in its weights\\n means it is not inside the training.\\nfrsq= hse\\n·)\\nWhy we should use RAG?\\n1:Limitedknowledgeaccess\\nLack of transparency: LLMs struggle to provide transparent or relevant information\\n3.Hallucinationsinanswers\\n2.RAG Architecture.\\n1. Ingestion\\n2. Retrieval\\n3. Generation\\nArchitecture\\nL0,1 0.3 0.33\\nQuestion\\ntextchunk\\nEmbedbingy -1\\ncResar'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 1, 'page_label': '2'}, page_content='cResar\\nueryEmbedeling\\nBuild\\nEmlbedking-2\\nSemantic\\nL0,1 0.3 0.33\\nExtractData/\\ntextchunk2\\nIndex\\nLLMGenerative\\nContent\\n10.30.3]\\nemanticSearch\\ntextchuk3\\nEmbedbing -3\\n[90h050]\\nLO.5 0.4 0.5]\\nnowledlge\\nRanked\\nEmbedeing-10\\nBase\\ntextchunk10\\nResults\\nQetaiva/ -)  6btaintnq\\nfhe dt frm D\\nAuq ment \\nehching.inf。\\nusmq.\\n心。\\nPronP)\\ngehrihon\\n人M\\nLkshq \\ncpr-'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 2, 'page_label': '3'}, page_content='embedd inq\\ny(oar)\\n√echr.=)\\nicar\\n[%]\\nP2=)[x0]\\nP3e [oy]\\nX\\n(ysom\\nower\\n<rng\\nTueeh\\n0.S.\\nMan°\\n0.13\\nSimlM\\nn\\nCosrhie smilanly\\necuLrdia \\nJaccare\\nFruil.\\nApple\\n[T,r]=[]\\nuys了\\n[][]\\n: Tech\\nSimiM?\\nhp 0@\\nCoSme =) Cos 90°'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 3, 'page_label': '4'}, page_content=\"3.End toEnd RAGPipeline.\\nLet'ssummariestheprocessofRAG:\\nBasic RAG Pipeline\\nIngestion\\nDocuments\\nEmbeddings\\nChunks\\nIndex\\nRetrieval\\nSynthesis\\nIndex\\nTopK\\nQuery\\nLLM\\nResponse\\nRAG Flow:A StepbyStep Representation\\nFigure 1 demonstrates thestepsinvolvedinbuildinga RAGpipeline:\\nLegend\\nExtraction， chunking\\nEnterprise Data Store \\nDatabricks, Anyscale, LangChan\\nContextual data\\nAIWS,MictosoftGoogleOracieDatabricks,\\nSnowllake MongoDB,CouchoB,DataStax\\nNotion, Codae, Salesforoe, JiRA, eto\\nUser Query\\nMany others.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 3, 'page_label': '4'}, page_content='Many others.\\nRetrieval engine\\nAction\\nText Storage DB\\nApp hosting\\nVercel,streamlit, Gradio,\\nreplit, fly.io\\nector Store /DB\\nQdrantPine\\nme,zl\\nEmbedding LLM\\na,P9N\\nOpenAiLCohere,\\nHuggingface\\nQuery\\nLLM hosting \\nMLOps\\nResponse\\nMLlow, W&B, Aim\\nConstruet prompt\\nLLM hosting\\nLangchein, Rebuff, DIY\\nOperALCohere,Anthropic\\nAzure, AWS, GCP\\nEnterprise App Automation\\nepiea asuodsa\\nZapier,JIRAtionod\\nAsana, Monday, email, etc\\nNvidia Guardrails'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 4, 'page_label': '5'}, page_content='A.).LetsunderstandtheIngestionprocess\\n1.Document:\\nIn a typical RAG pipeline, we have knowledge sources, such as Local Files, CSV, TSV, JSON, PDF, DOCs, Web pages,\\nXML,Databases,Cloud Storage,AnyRemoteLocation etc.\\n2. Chunking:\\nWe collect the data from yarious sources, split the data,into the chunks.\\nWhy chunking is required?\\nWe can fed the entire document alsobut why we are just passing the paragraph so here the reason is\\n1. LLM will rt be overloaded with information and\\nCcmini?.\\n)p9)\\n(GpT'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 4, 'page_label': '5'}, page_content=\"Ccmini?.\\n)p9)\\n(GpT\\n2.Evenit ishaving somelimitsinterms oftokens\\nHow tofiguring out theIdeal ChunkSize\\nToo small a chunk won't provide you info. It is not sufficient and These chrunks can be defined either by a fixed size, such\\nas a specific number of characters, sentences or paragraphs.\\nLarger chunks might include irrelevant information,\\nintroducing noise and potentially\\nHeducing the retrieval accuracy.By\\ncontrollinft\\nthechunksize\\nRAGcanmaintainabalancebetweencomprehensivenessandprecision.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 4, 'page_label': '5'}, page_content=\"Based on these factor you can' decide the size of chunk.\\nDa+s - CorP.as\\n1. DataCharacteristics\\nChuiic -) Doce amenlh.\\ntdc\\n2.Retriever Constraints\\n(s+n+ece)\\n3.Memory and Computational Resources\\n4TaskRequirements\\n5.Experimentation\\n6. OverlapConsideration\\n@hanics =) fokeins (wora )\\nhttps://www.pinecone.io/learn/chunking-strategies/\\nSenter o ( Doc, Chan k)\\nWo -d (T)\\nParagraa\\n3. Embedding\\nAfter chunking we convert it into vector embedding. vector embeddingare numerical representations of the data.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 4, 'page_label': '5'}, page_content='Types of embedding\\n1. Frequency based embedding\\nSe menh\\nBOW\\nmbeddrng\\nTF-IDF\\nN-GRAMS\\n>2. Neural Network based embeddings\\nWord2Vec\\nfasttext\\nBert\\nElmo\\nOPEN AI Embedding\\nGeminiEmbedding\\nToken level embedding vs Sentence level embedding.\\nCheckout the link: https: //huggingface.co/sentence-transformers\\nhttps://www.sbert.net/\\nwhich embedding model you need to select:\\nCheckouttheleaderboard:https://huggingface.co/spaces/mteb/leaderboard'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6'}, page_content='howsentencetransformersdiffercomparedtotoken-levelembeddingmodelssuchasBERT?\\nSentence transformers are specifically optimized for producing representations at the sentence level, focusing o\\ncapturing the overall semantics of sentences,which makes them particularly useful for tasks involving sentence similarit\\nand clustering. This contrasts with token-level models like BERT, which aremore focused on understanding an\\nrepresentingthemeaningofindividualtokenswithintheirwidercontext.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6'}, page_content='4. Vector Embedding Indexing\\ndimensionalvectordata,enablingfastsimilaritysearchesandnearestneighborqueries.\\nCheckout the link: https://www.datastax.com/guides/what-is-a-vector-index\\nAvectordatabase\\nindexes\\nandstores\\nvectorembeddings\\nvector indexing\\nfor fast retrieval\\nand similanitysearch.\\nIndex\\nJembecldlings\\n40.70.90.10.5\\n20.30.80.70.3\\n0.60.40.30.2\\nunstructuredl\\ndata\\n0.30.20.10.9\\ndatastructure\\nofteninclucingadistancemetric\\n5.Database or Retriever:'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6'}, page_content='Theretriever herecould beanyof thefollowingdependingontheneed\\nVectordatabase:Avectordatabaseindexesandstoresvectorembeddingsforfastretrievalandsimilaritysearch,with\\ncapabilities like CRUD operations, metadata filtering, horizontal scaling, and serverless.\\nGraph database:\\nGraph databases are designed to represent and store data as graphs.This makes it easy to represent\\npeople, products, and events along with what ties them together. Search engines, logistics businesses, and social networks'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6'}, page_content='typically.usegraphdatabasestounderstandconnectionsintheirdata.\\nNodes are the primary entities in a graph database. Each node holds all data about a person, product, business, event, or\\nanother entity.\\nEdges are theconnecting parts of graph databases. They showsimilarities, relationships, and commonalities.You can\\ndefine the properties and weights of edges tofit your purpose.\\nPegularSQLdatabase:Offersstructureddatastorageandretrievalbutmightlackthesemanticflexibilityofvector\\ndatabases.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6'}, page_content=\"databases.\\nGraph databases bring you the fullpower of relationships in data.\\nVector databases arebest suited for managing and querying high-dimensional data in use cases that require similarity\\nsearches.\\nIt can behard tomake theMice andgowith eithergraph or vector technology foryour database.Withgenerative AI,\\nlarge language models (LLM), and real-time data playing an increasing part in modern applications, we're seeing an\\nincreaseincombined solutions\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6'}, page_content=\"With generative AI, large language models (LLM), and real-time data playing an increasing part in modern applications,\\nwe'reseeinganincreasein'combinedsolutions.\\nThis is why Nee4j recently added the ability to perform vector similarity search.They aim to make more sense of data and\\ngraph\\ncheckout thelink:https://superlinked.com/vector-db-comparison/\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 6, 'page_label': '7'}, page_content=\"B).Let'sUnderstandtheretrievalprocess\\nStandardnaiveapproach\\nIn a basic RAG Pipeline\\nDocuments\\nChunks\\nThesametextchunksused in\\nembeddingsandsynthesis.\\nEmbeddingforretrieval\\nSynthesis\\ntasks\\nTopK\\nretrieved\\nEmbeddings\\nchunks\\nLLM\\nResponse\\nBut:\\nEmbedding-basedretrievalworkswellwith\\nsmallertextchunks.\\nThe standard pipeline uses the same text chunk for indexing/embedding as well as the output synthesis.\\nAdvantages:\\n·Simplicity and Efficiency\\n· Uniformity in Data Handling\\nDisadvantages:\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 6, 'page_label': '7'}, page_content='Disadvantages:\\n·Limited Contextual Understanding\\n·PotentialforSuboptimalResponses\\nSentence-WindowRetrieval / Small-to-Large.Chunking\\nInSentence-windowretrieval\\npipeline\\ncontext\\nDocuments\\nChunks\\nsmaller\\nContextaroundthechunks\\nchunks\\naddedtotheretrievedones\\nEmbeddingforretrieval\\nSynthesis\\ntasks\\nTopK\\nretrieved\\nEmbeddings\\nchunks\\nLLM\\nResponse'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 7, 'page_label': '8'}, page_content='During retrieval, we retrieve the sentences that are most relevant to the query via similarity search and replace the\\nsentence withthefull surrounding context(using a static sentence-window around the context,implemented by\\nretrievingsentencessurroundingtheonebeingoriginallyretrieved)\\nSentence-windowretrieval\\nQuery:Whatarethe\\nconcernssurrounding\\ntheAMOC?\\nContinuousobservationof theAtlantic\\nmeridionaloverturning circulation（AMoc)\\nhasimproved theunderstanding of its'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 7, 'page_label': '8'}, page_content='variability（Frajka-Williams et al,2019),but\\nthereislowconfidenceinthequalificationof\\nAMOC changesinthe2oth centurybecause\\nof lowagreementinquantitative\\nWhat theLLM sees\\nreconstructed andsimulated trends.Direct\\nobservationalrecords since the mid-2000s\\nremaintooshorttodetermine therelative\\ncontributions of internal variability,natural\\nforcingandanthropogenictoAMocchange\\n(highconfidence).Overthe 2lstcentury\\nAMOCwill very likelydeclineforallSsp\\nEmbeddingLookup\\nscenariosbutwillnotinvolveanabrupt'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 7, 'page_label': '8'}, page_content='collapsebefore2100.3.2.2.4Sea IceChanges\\nSea ice is akey driver of polar marine life,\\nhosting unique ecosystems and affecting\\ndiversemarineorganismsandfoodwebs\\nthroughitsimpactonlightpenetrationsand\\nWhattheLLMsees\\nsuppliesof nutrientsandorganicmatter(\\nArrigo, 2014).\\nAdvantages:\\n·Enhanced Specificity in Retrieval\\n·Context-Rich Synthesis\\n·Balanced Approach\\nDisadvantages:\\n?Increased Complexity\\nAuto-mergingRetriever/HierarchicalRetriever\\nAuto-merging retrieval\\nChunk\\nChunk\\n(512)\\n(512)\\nChunk\\nChunk'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 7, 'page_label': '8'}, page_content='(512)\\nChunk\\nChunk\\nChunk\\nChunk\\n(128)\\n(128)\\n(128)\\n(128)\\nChunk\\nChunk\\nChunk\\nChunk\\n(128)\\n(128)\\n(128)\\n(128)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 8, 'page_label': '9'}, page_content='Auto-mergingretrieval aimsto.combine(or merge)informationfrommultiple sources orsegments of text tocreate a\\nmore comprehensive and contextually relevant response to a query.This approach isparticularly useful when no single\\ndocument orsegmentfully answersthequerybutrather the answerliesin combininginformationfrommultiplesources.\\nIt allows smaller chunks to be merged into bigger parent chunks. It does this via the following steps:\\nDefineahierarchyofsmallerchunkslinkedtoparentchunks:'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 8, 'page_label': '9'}, page_content='If the set of smaller chunks linking to a parent chunk exceeds some threshold (say,cosine similarity),then“merge\\nsmaller chunks into thebigger parent chunk.\\nThe methodwillfinallyretrievetheparentchunkforbettercontext.\\nAdvantages:\\n·ComprehensiveContextualResponses\\n·ReducedFragmentation\\n· Dynamic Content Integration\\nDisadvantages:\\n·Complexity in Hierarchy and Threshold Management\\n·Risk of Overgeneralization\\n·Computational Intensity\\nEnsemble Retrieval and Re-Ranking\\nAll documerts\\nQuery\\nJerry Liu'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 8, 'page_label': '9'}, page_content='Query\\nJerry Liu\\n@jeryjliue\\nMM？\\nVector\\nIf you 1) already know RAG basics, and 2) want to become a superstar Al\\nDB\\nengineer, then learn to build advanced RAG from scratch \\nExcited to launch a new category of @llamaindex tutorials on this exact\\ntopic：\\nlearn advanced IR/Al concepts\\ntacklemore complex userqueries\\nImprove accuracy + reduce hallucination\\nIn this first part, we teach youhow to build a RAG-Fusion pipeline:\\nenables dynamic retrieval over complex questions.\\nA two=stage ret'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 8, 'page_label': '9'}, page_content=\"A two=stage ret\\nQuery generation/rewriting\\n2Ensemble retrieval\\n3Reciprocal RankFusion\\nAllthese steps are based off core retrieval principles, designed to\\nimprove precision/recall for different user queries.By learning this, you'll\\nswess gg ino Bujzjwgdo jo, suoynul/sjoo au uje\\nLearnByBullding.Al\\nUserQuery\\nRetriever1\\nRetriever2\\nRetriever3\\nChunk size:128\\nChunk size:512\\nChunk size:1024\\nChunk(128)\\nChunk(512)\\nChunk(128)\\nChunk(1024)\\nChunk（512)\\nChunk(1024)\\nReranker\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 9, 'page_label': '10'}, page_content=\"Let's Understand the augmentation andgeneration\\nResponseGeneration/Synthesis\\nUser Input: A user provides a query in natural language, seeking an answer or completion.\\nInformationRetrieval:Theretrievalmechanismscansthevectordatabasetoidentifysegmentsthataresemantically\\nsimilar to the user's query (which is also embedded).These segments are then given to the LLM to enrich its context for\\ngeneratingresponses.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 9, 'page_label': '10'}, page_content=\"Combining Data: The chosen data'segments from the database are combined with the user's initial query, creating an\\nexpandedprompt.\\nGenerating Text: The enlarged prompt, filled with added context, is then given to the LLM, which crafts the final, context-\\nawareresponse.\\nThis process involves integrating the insights gleaned from various sources, ensuring accuracy and relevance, and crafting\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 9, 'page_label': '10'}, page_content=\"a response that is not only informative but also aligns with the user's original query, maintaining a natural and\\nconversationaltone.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 10, 'page_label': '11'}, page_content=\"Benefits of RAG:\\n·With-RAG, the LLM is able to leverage knowledge and information that is not necessarily in its weights, providing it\\naccesstoexternalknowledgebases.\\n· Improved relevance and accuracy:\\n·Handling open-domain queries:\\n·Reduced generation bias:\\n·Multi-modal capabilities:\\n·image captioning, content summarization\\n.Human-AI Collaboration:\\n·RAGdoesn'trequiremodelretraining,savingtime andcomputationalresources.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 10, 'page_label': '11'}, page_content=\"In summary, RAG models are well-suited for applications where there's a lot of information available, but it's not neatly\\norganised or labelled.\\nDisadvantage:\\nRAG's performance depends on the comprehensiveness and correctness of the retriever's knowledge base.\\nInformationLoss\\nIf welook at the chain of processes in theRAG system:\\n1.Chunkingthe.textandgeneratingembeddingforthechunks\\n2.Retrievingthechunksbysemanticsimilaritysearch\\n3.Generateresponsebasedonthetextofthetop_kchunks\\nWayofcreatingaRAG.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 10, 'page_label': '11'}, page_content='WayofcreatingaRAG.\\nRAG libraries and frameworks\\nBuild your onRAGfromscratch\\nLang chain\\nLlama Index.\\nHaystack: End-to-end RAG framework for document search provided by Deepset\\nREALM: Retrieval Augmented Language Model (REALM) training is a Google toolkit for\\nopen-domain question answering with RAG.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 11, 'page_label': '12'}, page_content='RAG(Retrieval Augmented Generation)Cheatsheet\\nStages in RAG:\\nKey Concepts:\\n1.Loading:\\n1.Nodes and Documents:\\n Imgort your data (text fles, PFs, databases, APIs using Lamaub’s extense range f\\nFundamental units in Llamatndex, where Documents encapsulate data sources and Nodes represent\\nconnectors.\\ndata “chunks* with associated metadata.\\n2.Indexing:\\n1.Connectors:\\nCreate searchable data structures, primarlythrouh vecterembeddings andmetadata strateies,'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 11, 'page_label': '12'}, page_content='Bridge arious dataseurce int the RAG frmwrk, transfrming theint odes and cume\\neapa xaas tuaa fuqeua\\n1.Indexes:\\n3.Storing:\\no Securely store your indexed data and metadata for quick access without the need to re-index.\\nmetadata.\\n4.Querying:\\n1.Embeddings:\\no Utilize LLMs and Llamalndex data structures for diverse querying techniques, including sub-\\nNumerical representations of data, facilitating the relevance fitering preces.\\nqueries and hybrid strategies.\\n1.Retrievers:\\n5.Evaluation:'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 11, 'page_label': '12'}, page_content='5.Evaluation:\\nDefine efficient retrieval strategles, ensuring the relevancy and efficiency of deta retrieval.\\n Continuouslyassess the effectiveness of your pipeline to ensure accuracy, faithflness, and\\n1.Routers:\\npaads asuodsai\\nManage the selectien f appropriate retrievers based on query speciis and metaata.\\n1.Node Postprocessors:\\nApply transformations or re-ranking logic to refine the set of retrieved nodes.\\n1.Response Synthesizers:\\nApplicationTypes:\\nCraft responses from the LLM, util'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 11, 'page_label': '12'}, page_content='1.Query Engines:\\n For dinect question-answering over your data.\\n2.Chat Engines:\\nLlamalndex\\nSingleStore\\n Enables coversations with your data for an interactive experience.\\n3.Agents:\\nAutomated decision-makers that interact with external too\\nadaptable for complex tasks.\\nLangChain\\nOpenAl\\nConstructior\\nRetrieval\\nRelationalDBs\\nGraphDBs\\nVectorbBs\\nRarking\\nRefinerent\\nestien→\\nduestion→\\nGuestio\\nText-to-SQL\\nText-to-Cypher\\nSelf-query retriever\\nal Language to SQL\\nNatural Language to Cypher'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 11, 'page_label': '12'}, page_content='Auto-generatemetadata\\nd/orSQLw/PGVector\\nquery Langugage for GraphDBs\\nfilters fron query\\nRe-Rank,RankGPT,RAG-Fusion\\nCRAG\\nQuery\\nTranslation\\nRank or filter/compress docu\\nments based on relevance\\nQuery Decomposition\\nPsuedo\\neuments\\nAetiveretieval\\nCRAG\\nQuestion\\nQuestion\\nMulti-query, Step-back, RAG-Fusion\\nHyDE\\nRe-retrieve and/or retrive fron new data sources\\n(e.g.,wb）if retrieved documents aze not relevant\\nDecompose or re-phrase the input question\\nHypothetical documents\\nyeog\\nDiagramcreditLangchain'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 11, 'page_label': '12'}, page_content=\"Question\\nAnswer\\nRelationalDB\\nDocuments\\nSteveNouri\\npt\\nVeetorstore\\nPrompt#2\\nLet LLM choose DB based\\nEnbed question and choose\\non the question\\nprompt based on sinilarity\\nIncl\\nGeneration\\nChunk Optimization\\nMulti-representation\\nHeirachicalIndeing\\nActiveretieval\\nCharecters\\nSectiors\\nSenant'ic\\nT'0]\\nDeliniters\\nSelf-RAG, RRR\\nSenantic Splitter\\nParent Document,Dense X\\nFine-tuning,ColBERT\\nRAPTOR\\nOptimize chunk size\\nConvert documents into compact\\nDomain-specific and/or\\nTree of document sumnarization\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12, 'page': 11, 'page_label': '12'}, page_content='Use generation quality to inform\\nused for eabedding\\nretrieval units （e.g.,a sunmary)\\nadvanced enbedding model.s\\nat various abstraction Levels\\nquestion re-writing and/or\\nre-retrieval of documents')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Weaviate\n",
    "\n",
    "vector_db = Weaviate.from_documents(\n",
    "    docs,embeddings, client=client,by_text=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'creationdate': '', 'creator': 'PyPDF', 'page': 11, 'page_label': '12', 'producer': 'PyPDF', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12}, page_content='RAG(Retrieval Augmented Generation)Cheatsheet\\nStages in RAG:\\nKey Concepts:\\n1.Loading:\\n1.Nodes and Documents:\\n Imgort your data (text fles, PFs, databases, APIs using Lamaub’s extense range f\\nFundamental units in Llamatndex, where Documents encapsulate data sources and Nodes represent\\nconnectors.\\ndata “chunks* with associated metadata.\\n2.Indexing:\\n1.Connectors:\\nCreate searchable data structures, primarlythrouh vecterembeddings andmetadata strateies,'), Document(metadata={'creationdate': '', 'creator': 'PyPDF', 'page': 10, 'page_label': '11', 'producer': 'PyPDF', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12}, page_content=\"In summary, RAG models are well-suited for applications where there's a lot of information available, but it's not neatly\\norganised or labelled.\\nDisadvantage:\\nRAG's performance depends on the comprehensiveness and correctness of the retriever's knowledge base.\\nInformationLoss\\nIf welook at the chain of processes in theRAG system:\\n1.Chunkingthe.textandgeneratingembeddingforthechunks\\n2.Retrievingthechunksbysemanticsimilaritysearch\\n3.Generateresponsebasedonthetextofthetop_kchunks\\nWayofcreatingaRAG.\"), Document(metadata={'creationdate': '', 'creator': 'PyPDF', 'page': 1, 'page_label': '2', 'producer': 'PyPDF', 'source': 'RAG_From_Scratch.pdf', 'total_pages': 12}, page_content='1.Introduction:WhatisRAG?\\nRAG is called Retrieval augmented generation, is an architecture used to help LLMs model like gpt- 4,\\nGemini, Gemma,LLAMA2, MISTRAL to provide a-better response by using relevant information from\\nadditional sources andreduces thechancethatllm-willleadtoincorrectinformation\\nor\\nRAG is a technique that enhances language model generation by incorporating external knowledge.This\\nis typically doneby retrievingrelevantinformation from alarge corpus of documents and usingthat')]\n"
     ]
    }
   ],
   "source": [
    "print(vector_db.similarity_search(\"what is rag?\", k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG(Retrieval Augmented Generation)Cheatsheet\n",
      "Stages in RAG:\n",
      "Key Concepts:\n",
      "1.Loading:\n",
      "1.Nodes and Documents:\n",
      " Imgort your data (text fles, PFs, databases, APIs using Lamaub’s extense range f\n",
      "Fundamental units in Llamatndex, where Documents encapsulate data sources and Nodes represent\n",
      "connectors.\n",
      "data “chunks* with associated metadata.\n",
      "2.Indexing:\n",
      "1.Connectors:\n",
      "Create searchable data structures, primarlythrouh vecterembeddings andmetadata strateies,\n"
     ]
    }
   ],
   "source": [
    "print(vector_db.similarity_search(\"what is rag?\", k=3)[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In summary, RAG models are well-suited for applications where there's a lot of information available, but it's not neatly\n",
      "organised or labelled.\n",
      "Disadvantage:\n",
      "RAG's performance depends on the comprehensiveness and correctness of the retriever's knowledge base.\n",
      "InformationLoss\n",
      "If welook at the chain of processes in theRAG system:\n",
      "1.Chunkingthe.textandgeneratingembeddingforthechunks\n",
      "2.Retrievingthechunksbysemanticsimilaritysearch\n",
      "3.Generateresponsebasedonthetextofthetop_kchunks\n",
      "WayofcreatingaRAG.\n"
     ]
    }
   ],
   "source": [
    "print(vector_db.similarity_search(\"what is rag?\", k=3)[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template=\"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use ten sentences maximum and keep the answer concise.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "huggingfacehub_api_token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "if huggingfacehub_api_token:\n",
    "    print(\"Token loaded successfully\")\n",
    "else:\n",
    "    print(\"Failed to load token. Check .env file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HuggingFaceHub(\n",
    "    huggingfacehub_api_token=huggingfacehub_api_token,\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    model_kwargs={\"temperature\":1, \"max_length\":180}\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever,  \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Query was not successful.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteDisconnected\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\urllib3\\connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\http\\client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\http\\client.py:287\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemote end closed connection without\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mRemoteDisconnected\u001b[0m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 841\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    844\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\urllib3\\util\\retry.py:474\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\urllib3\\util\\util.py:38\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\urllib3\\connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\http\\client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\http\\client.py:287\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemote end closed connection without\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\weaviate\\gql\\filter.py:120\u001b[0m, in \u001b[0;36mGraphQL.do\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/graphql\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweaviate_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RequestsConnectionError \u001b[38;5;28;01mas\u001b[39;00m conn_err:\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\weaviate\\connect\\connection.py:459\u001b[0m, in \u001b[0;36mConnection.post\u001b[1;34m(self, path, weaviate_object, params)\u001b[0m\n\u001b[0;32m    457\u001b[0m request_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_version_path \u001b[38;5;241m+\u001b[39m path\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweaviate_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_request_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_proxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\requests\\sessions.py:637\u001b[0m, in \u001b[0;36mSession.post\u001b[1;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \n\u001b[0;32m    629\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\requests\\adapters.py:682\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mConnectionError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mrag_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhat is rag system?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\langchain_core\\runnables\\base.py:3014\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3012\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m   3013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3014\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3015\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3016\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\langchain_core\\runnables\\base.py:3721\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3716\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m   3717\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3718\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[0;32m   3719\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   3720\u001b[0m         ]\n\u001b[1;32m-> 3721\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   3722\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3723\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\langchain_core\\runnables\\base.py:3721\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3716\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m   3717\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3718\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[0;32m   3719\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   3720\u001b[0m         ]\n\u001b[1;32m-> 3721\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   3722\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3723\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\concurrent\\futures\\_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\langchain_core\\runnables\\base.py:3705\u001b[0m, in \u001b[0;36mRunnableParallel.invoke.<locals>._invoke_step\u001b[1;34m(step, input, config, key)\u001b[0m\n\u001b[0;32m   3703\u001b[0m context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   3704\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m-> 3705\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3707\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3709\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\langchain_core\\retrievers.py:259\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 259\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28minput\u001b[39m, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs\n\u001b[0;32m    261\u001b[0m     )\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    263\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\langchain_core\\vectorstores\\base.py:1073\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1071\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs \u001b[38;5;241m|\u001b[39m kwargs\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1073\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n\u001b[0;32m   1074\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1075\u001b[0m     docs_and_similarities \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1076\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search_with_relevance_scores(\n\u001b[0;32m   1077\u001b[0m             query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs\n\u001b[0;32m   1078\u001b[0m         )\n\u001b[0;32m   1079\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\langchain_community\\vectorstores\\weaviate.py:193\u001b[0m, in \u001b[0;36mWeaviate.similarity_search\u001b[1;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_embedding cannot be None for similarity_search when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_by_text=False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m     )\n\u001b[0;32m    192\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding\u001b[38;5;241m.\u001b[39membed_query(query)\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_by_vector(embedding, k, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\langchain_community\\vectorstores\\weaviate.py:238\u001b[0m, in \u001b[0;36mWeaviate.similarity_search_by_vector\u001b[1;34m(self, embedding, k, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditional\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    237\u001b[0m     query_obj \u001b[38;5;241m=\u001b[39m query_obj\u001b[38;5;241m.\u001b[39mwith_additional(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditional\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m--> 238\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mquery_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_near_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_limit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\weaviate\\gql\\get.py:1905\u001b[0m, in \u001b[0;36mGetBuilder.do\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m   1904\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vikas\\OneDrive\\Desktop\\Generative-AI-Sunny-Sir\\genai\\lib\\site-packages\\weaviate\\gql\\filter.py:122\u001b[0m, in \u001b[0;36mGraphQL.do\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    120\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mpost(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/graphql\u001b[39m\u001b[38;5;124m\"\u001b[39m, weaviate_object\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: query})\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RequestsConnectionError \u001b[38;5;28;01mas\u001b[39;00m conn_err:\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsConnectionError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery was not successful.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconn_err\u001b[39;00m\n\u001b[0;32m    124\u001b[0m res \u001b[38;5;241m=\u001b[39m _decode_json_response_dict(response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery was not successful\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mConnectionError\u001b[0m: Query was not successful."
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"what is rag system?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
